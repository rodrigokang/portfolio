{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset Allocation with Unsupervised Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have $M$ assets with prices $\\left\\{ S_t^{(k)} \\right\\}_{k=1}^M$, where the quantity of the $k$-th asset at time $t$ is denoted by $x_t^{(k)}$. The investment in the $k$-th asset at time $t$ is given by $V_t^{(k)} = S_t^{(k)} \\cdot x_t^{(k)}$. Since a portfolio is a linear combination of financial assets, the value of the portfolio $\\Pi_{t}$ at each instant is determined by the specific combination of assets held at that moment:\n",
    "\n",
    "$$\n",
    "\\Pi_{t} = \\sum_{k=1}^M V_t^{(k)}\n",
    "$$\n",
    "\n",
    "The value of a portfolio can change either due to a change in the prices of the assets it contains, a rebalancing of its composition, or both. Generally, the returns of the assets over a given investment horizon are represented by an $M$-dimensional random vector $\\mathbf{R}_{t}$, defined as:\n",
    "\n",
    "$$\n",
    "\\mathbf{R}_{t} = \\left[ R_t^{(1)}, R_t^{(2)}, \\dots, R_t^{(M)} \\right]^T\n",
    "$$\n",
    "\n",
    "where $R_t^{(k)} = \\frac{S_{t+1}^{(k)} - S_t^{(k)}}{S_t^{(k)}}, \\,\\,\\, \\forall k = 1, 2, \\dots, M$. The expected return of the assets over an investment horizon is then a real (deterministic) vector given by the expected value of the random return vector, i.e.,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu}_{t} = \\mathbb{E}\\left[\\mathbf{R}_{t}\\right] \\in \\mathbb{R}^M\n",
    "$$\n",
    "\n",
    "The return of a portfolio is the percentage change in the $\\text{P\\&L}$ based on an initial reference level, which can be taken as the size of the initial position. The $\\text{P\\&L}$ (Profit and Loss) refers to the economic outcome of a trading operation over a certain period. This can be due to capital appreciations of a portfolio $\\Pi_{t}$, the receipt of dividends from stocks, coupon payments from bonds, etc. Mathematically, we can express the $\\text{P\\&L}$ in discrete time as $\\text{P\\&L}_{t+1} = \\Delta\\Pi_{t+1} = \\Pi_t - \\Pi_{t-1}$. Thus, the return of a portfolio over an investment horizon $\\Delta t$ is given by:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "R_{\\mathbf{w}} & = \\frac{\\Pi_{t+1} - \\Pi_t}{\\Pi_{t}} \\\\\n",
    "               & = \\frac{\\sum_{k=1}^M V_{t+1}^{(k)} - \\sum_{k=1}^M V_t^{(k)}}{\\Pi_t} \\\\\n",
    "               & = \\frac{\\sum_{k=1}^M \\left( V_{t+1}^{(k)} - V_t^{(k)}\\right)}{\\Pi_t} \\\\\n",
    "               & = \\frac{\\sum_{k=1}^M \\Delta V_{t+1}^{(k)}}{\\Pi_t} \\\\\n",
    "               & = \\sum_{k=1}^M \\frac{\\Delta V_{t+1}^{(k)}}{\\Pi_t} \\\\\n",
    "               & = \\sum_{k=1}^M \\frac{V_t^{(k)}}{\\Pi_t} \\frac{\\Delta V_{t+1}^{(k)}}{V_t^{(k)}} \\\\\n",
    "               & = \\sum_{k=1}^M \\frac{V_t^{(k)}}{\\sum_{k=1}^M V_t^{(k)}} \\frac{\\Delta V_{t+1}^{(k)}}{V_t^{(k)}} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Assuming the quantity of the $k$-th asset $x_t^{(k)}$ remains fixed during the investment horizon, the term $\\frac{\\Delta V_{t+1}^{(k)}}{V_t^{(k)}}$ equals the return of the $k$-th asset at time $t$. Moreover, defining the portfolio weight of the $k$-th asset at time $t$ as:\n",
    "\n",
    "$$\n",
    "w_t^{(k)} = \\frac{V_t^{(k)}}{\\Pi_{t}} = \\frac{V_t^{(k)}}{\\sum_{k=1}^M V_t^{(k)}}\n",
    "$$\n",
    "\n",
    "we find that the discrete return of the entire portfolio can be written as the weighted average of the discrete returns of its constituent assets:\n",
    "\n",
    "$$\n",
    "R_{\\mathbf{w}} = \\sum_{k=1}^M w_t^{(k)} R_t^{(k)}\n",
    "$$\n",
    "\n",
    "In finance, if $w_t^{(k)} > 0$, the $k$-th asset is said to be \"Long\", and if $w_t^{(k)} < 0$, the $k$-th asset is said to be \"Short\".\n",
    "\n",
    "To simplify the notation, we can define the portfolio composition as an $M$-component vector where each component represents the individual weights of each asset:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_t = \\mathbf{w}_t(\\mathbf{S}_t) = \\left[ w_t^{(1)}, w_t^{(2)}, \\dots, w_t^{(M)} \\right]^T\n",
    "$$\n",
    "\n",
    "Therefore, the discrete return of the entire portfolio over the holding period is given by:\n",
    "\n",
    "$$\n",
    "R_{\\mathbf{w}} = \\mathbf{w}_t^T\\mathbf{R}_t\n",
    "$$\n",
    "\n",
    "and the expected return of the portfolio $\\Pi$ is:\n",
    "\n",
    "$$\n",
    "\\mu_{\\Pi} = \\mathbb{E}\\left[ R_{\\mathbf{w}} \\right] = \\mathbb{E}\\left[ \\mathbf{w}_t^T\\mathbf{R}_t \\right] = \\mathbf{w}_t^T \\mathbb{E}\\left[ \\mathbf{R}_t \\right] = \\mathbf{w}_t^T \\boldsymbol{\\mu}_{t} \\in \\mathbb{R}\n",
    "$$\n",
    "\n",
    "Another important quantity to measure is the risk, which can be defined as the variation between what is expected and what is observed. If we expect the return of an asset, it is reasonable to think of risk as the fluctuation of the expected return. There are several metrics to measure this fluctuation, but in this project, we will use **variance**. On one hand, if we calculate the variance of the return vector:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Var}\\left[ \\mathbf{R}_{t} \\right] \n",
    "& = \\mathbb{E}\\left[ \\left(\\mathbf{R}_{t} - \\mathbb{E}\\left[ \\mathbf{R}_{t} \\right] \\right)^2 \\right] \\\\\n",
    "& = \\mathbb{E}\\left[ \\left(\\mathbf{R}_{t} - \\boldsymbol{\\mu}_{t} \\right)\\left(\\mathbf{R}_{t} - \\boldsymbol{\\mu}_{t} \\right)^T \\right] \\\\ \\\\\n",
    "& = \\mathbb{E}\n",
    "\\left[  \n",
    "\\begin{pmatrix}\n",
    "R_t^{(1)} - \\mu_t^{(1)} \\\\ \\\\\n",
    "\\vdots \\\\\n",
    "R_t^{(M)} - \\mu_t^{(M)}\n",
    "\\end{pmatrix}\n",
    "\\left( R_t^{(1)} - \\mu_t^{(1)}, \\dots, R_t^{(M)} - \\mu_t^{(M)} \\right)\n",
    "\\right] \\\\ \\\\\n",
    "& = \n",
    "\\begin{pmatrix}\n",
    "\\mathbb{E}\\left[ \\left(R_t^{(1)} - \\mu_t^{(1)}\\right)\\left(R_t^{(1)} - \\mu_t^{(1)}\\right) \\right] & \\cdots & \\mathbb{E}\\left[ \\left(R_t^{(1)} - \\mu_t^{(1)}\\right)\\left(R_t^{(M)} - \\mu_t^{(M)}\\right)\\right]\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\mathbb{E}\\left[\\left(R_t^{(M)} - \\mu_t^{(M)}\\right)\\left(R_t^{(1)} - \\mu_t^{(1)}\\right)\\right] & \\cdots & \\mathbb{E}\\left[ \\left(R_t^{(M)} - \\mu_t^{(M)}\\right)\\left(R_t^{(M)} - \\mu_t^{(M)}\\right)\\right]\n",
    "\\end{pmatrix} \\\\ \\\\\n",
    "& =\n",
    "\\begin{pmatrix}\n",
    "\\text{Var}\\left[ R_t^{(1)} \\right] & \\cdots & \\text{Cov}\\left[ R_t^{(1)}, R_t^{(M)} \\right]\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}\\left[ R_t^{(M)}, R_t^{(1)} \\right] & \\cdots & \\text{Var}\\left[ R_t^{(M)} \\right]\n",
    "\\end{pmatrix} \\\\ \\\\\n",
    "& = \\boldsymbol{\\Sigma}_t\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "In other words, the variance of the random return vector is the covariance matrix. Using this expression, we can calculate the portfolio risk as follows:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Var}\\left[ R_{\\mathbf{w}} \\right] \n",
    "& = \\text{Var}\\left[ \\mathbf{w}_t^T\\mathbf{R}_t \\right] \\\\\n",
    "& = \\mathbb{E}\\left[ \\left( \\mathbf{w}_t^T\\mathbf{R}_t - \\mathbf{w}_t^T\\boldsymbol{\\mu}_{t} \\right)\\left( \\mathbf{w}_t^T\\mathbf{R}_t - \\mathbf{w}_t^T\\boldsymbol{\\mu}_{t} \\right)^T \\right] \\\\\n",
    "& = \\mathbb{E}\\left[ \\mathbf{w}_t^T \\left(\\mathbf{R}_t - \\boldsymbol{\\mu}_{t}\\right)\\left(\\mathbf{R}_t - \\boldsymbol{\\mu}_{t}\\right)^T \\mathbf{w}_t \\right] \\\\\n",
    "& = \\mathbf{w}_t^T \\mathbb{E}\\left[\\left(\\mathbf{R}_t - \\boldsymbol{\\mu}_{t}\\right)\\left(\\mathbf{R}_t - \\boldsymbol{\\mu}_{t}\\right)^T \\right]\\mathbf{w}_t \\\\ \\\\\n",
    "& = \\mathbf{w}_t^T \\boldsymbol{\\Sigma}_t\\mathbf{w}_t \\in \\mathbb{R}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Portfolios Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have established the following:\n",
    "\n",
    "- **Portfolio composition** $\\Pi$ at each time $t$: $\\mathbf{w}_t$\n",
    "- **Portfolio return**: $R_{\\mathbf{w}} = \\mathbf{w}_t^T\\mathbf{R}_t$\n",
    "- **Expected portfolio return**: $\\mu_\\Pi = \\mathbb{E}\\left[ R_{\\mathbf{w}} \\right] = \\mathbf{w}_t^T \\boldsymbol{\\mu}_{t}$\n",
    "- **Portfolio risk**: $\\text{Var}\\left[ R_{\\mathbf{w}} \\right] = \\sigma_\\Pi^2 = \\mathbf{w}_t^T \\boldsymbol{\\Sigma}_t\\mathbf{w}_t$\n",
    "\n",
    "At this stage, it's relevant to ask whether it's possible to choose the portfolio composition $\\mathbf{w}_t$ in such a way that it provides an optimal balance between risk and return. There are various approaches to tackle this problem, with perhaps the most well-known being the **Modern Portfolio Theory** developed by **Harry Markowitz** in 1952. However, in this project, we will take a different approach based on a widely recognized unsupervised machine learning technique called **Principal Component Analysis (PCA)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a widely used statistical technique for dimensionality reduction in datasets. This method identifies the directions in which the data exhibit the greatest variability and transforms the data into a new coordinate system based on these directions. PCA was developed by Karl Pearson in 1901 and later refined by Harold Hotelling in the 1930s.\n",
    "\n",
    "PCA is an unsupervised method, meaning it relies solely on a set of features $X_1, X_2, \\dots, X_M$ without considering any associated response variable $Y$. Although its primary use is for dimensionality reduction, it is also applied in supervised learning problems, for example, by using the principal components as predictors in machine learning algorithms instead of the larger original set of variables. Additionally, PCA is a powerful tool for data visualization.\n",
    "\n",
    "PCA transforms the data into a new coordinate system where the principal components represent the greatest variability in the data. These components are sequences of unit vectors that optimally fit the data, minimizing the average squared perpendicular distance between the points and the line. The directions of the principal components correspond to those in the feature space along which the data show the greatest variability, defining lines and subspaces that closely approximate the data cloud.\n",
    "\n",
    "One of the main advantages of PCA is its ability to summarize a large set of correlated variables into a smaller number of representative variables that, together, explain most of the variability of the original set. This is especially useful in contexts with a large number of variables, where visualizing the data becomes a challenge. For example, if you have $N$ observations and a set of $M$ features $X_1, X_2, \\dots, X_M$, you could generate $\\binom{M}{2} = \\frac{M(M - 1)}{2}$ scatterplots to visualize the data. This means that for $M = 10$, there would be 45 possible scatterplots, which can become impractical if $M$ is large. Moreover, it's likely that none of these plots alone would be informative, as each captures only a fraction of the total information. Clearly, a more efficient method is needed to visualize the $N$ observations when $M$ is large, and this is where PCA is particularly useful.\n",
    "\n",
    "PCA allows for finding a low-dimensional representation of the data that captures as much variation as possible. While each of the $N$ observations resides in an $M$-dimensional space, not all of these dimensions are equally relevant. PCA identifies a small number of dimensions that are the most interesting, where the degree of interest is measured by the amount of variation in the observations along each dimension. Each of these dimensions is a linear combination of the original $M$ features.\n",
    "\n",
    "Therefore, PCA provides an effective solution for dimensionality reduction and data visualization in a low-dimensional space. For example, if two principal components can be derived that capture most of the variability in the data, the observations can be represented in a two-dimensional scatterplot, making it easier to identify patterns and clusters of related data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we explain the procedure for finding the principal components. Before diving into the details, it's worth noting that in PCA, the variables should be centered so that they have a mean of zero. Additionally, the results obtained when performing PCA also depend on whether the variables have been individually scaled (i.e., each multiplied by a different constant).\n",
    "\n",
    "What we seek is a mapping that transforms the original features $X_1, X_2, \\dots, X_M$ into new features $Z_1, Z_2, \\dots, Z_M$ in such a way that the variance is maximized, subject to the constraint that the column vectors forming the matrix representation of this transformation have unit norm. Mathematically, this means that the first principal component of the transformed feature set is the normalized linear combination of the features:\n",
    "\n",
    "$$\n",
    "Z_1 = \\gamma_{11}X_1 + \\gamma_{21}X_2 + \\dots + \\gamma_{M1}X_M = \\sum_{j=1} \\gamma_{j1}X_j = \\boldsymbol{\\gamma}_1^T \\mathbf{X} = \n",
    "\\left( \\gamma_{11}, \\gamma_{21}, \\dots, \\gamma_{M1} \\right)\n",
    "\\begin{bmatrix}\n",
    "X_1 \\\\\n",
    "X_2 \\\\\n",
    "\\vdots \\\\\n",
    "X_M\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We refer to the elements $\\gamma_{11}, \\gamma_{21}, \\dots, \\gamma_{M1}$ as the loadings of the first principal component; collectively, the loadings form the principal component loading vector, $\\boldsymbol{\\gamma}_1 = (\\gamma_{11}, \\gamma_{21}, \\dots, \\gamma_{M1})^T$. We constrain the loadings so that their sum of squares equals one, as otherwise, making these elements arbitrarily large in absolute value could result in an arbitrarily large variance. Therefore, to obtain the first principal component, we need to find the linear combination of the feature values that has the highest sample variance subject to the constraint $\\lVert \\gamma_1 \\rVert^2 = \\sum_{j=1}^M \\gamma_{j1}^2 = 1$. In other words, the first principal component loading vector solves the following constrained optimization problem:\n",
    "\n",
    "$$\n",
    "\\max_{\\gamma_{11}, \\dots, \\gamma_{M1}} \\left\\{ \\text{Var}\\left[ Z_1 \\right] \\right\\}, \\,\\,\\, \\text{subject to} \\,\\,\\, \\lVert \\boldsymbol{\\gamma_1} \\rVert^2 = 1\n",
    "$$\n",
    "\n",
    "For convenience, we write the variance of $Z_1$ in matrix form, which is the objective function:\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left[ Z_1 \\right] = \\text{Var}\\left[ \\boldsymbol{\\gamma}_1^T \\mathbf{X} \\right] = \\boldsymbol{\\gamma}_1^T \\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_1\n",
    "$$\n",
    "\n",
    "Thus, the problem takes the form:\n",
    "\n",
    "$$\n",
    "\\max_{\\gamma_{11}, \\dots, \\gamma_{M1}} \\left\\{ \\boldsymbol{\\gamma}_1^T \\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_1 \\right\\}, \\,\\,\\, \\text{subject to} \\,\\,\\, \\boldsymbol{\\gamma}_1^T \\boldsymbol{\\gamma}_1 = 1\n",
    "$$\n",
    "\n",
    "A well-known method for solving constrained optimization problems is the method of Lagrange multipliers. For our problem, the Lagrangian is defined as the objective function minus a constant for each of the constraints:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\gamma}_1) = \\boldsymbol{\\gamma}_1^T\\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_1 - \\lambda_1\\left( \\boldsymbol{\\gamma}_1^T\\boldsymbol{\\gamma}_1 - 1 \\right)\n",
    "$$\n",
    "\n",
    "To maximize the Lagrangian, we must find its critical points:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\gamma}_1} \n",
    "& = \\Sigma\\boldsymbol{\\gamma}_1 + \\boldsymbol{\\gamma}_1^T\\Sigma - \\lambda_1\\boldsymbol{\\gamma}_1 - \\lambda_1\\boldsymbol{\\gamma}_1^T \\\\\n",
    "& = \\Sigma\\boldsymbol{\\gamma}_1 + \\Sigma\\boldsymbol{\\gamma}_1 - \\lambda_1\\mathbb{1}\\boldsymbol{\\gamma}_1 - \\lambda_1\\mathbb{1}\\boldsymbol{\\gamma}_1^T \\\\\n",
    "& = 2\\Sigma\\boldsymbol{\\gamma}_1 - 2\\lambda_1\\mathbb{1}\\boldsymbol{\\gamma}_1 \\\\\n",
    "& = 2\\left(\\Sigma- \\lambda_1\\mathbb{1}\\right)\\boldsymbol{\\gamma}_1  \\\\\n",
    "& = \\boldsymbol{0} \\\\ \\\\\n",
    "& \\Rightarrow \\left(\\Sigma - \\lambda_1\\mathbb{1}\\right)\\boldsymbol{\\gamma}_1 = \\boldsymbol{0}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "By the Rouché–Frobenius theorem, for a homogeneous system of equations to have non-trivial solutions, the associated matrix must be singular, which means its determinant is zero: $\\text{det}\\left(\\Sigma - \\lambda_1\\mathbb{1}\\right) = 0$. This implies that $\\lambda_1$ is an eigenvalue of the covariance matrix $\\Sigma$. Additionally, we know that since the covariance matrix $\\Sigma$ is $M \\times M$ and positive definite, it has exactly $M$ eigenvalues $\\lambda_i, \\, i = 1, 2, \\dots, M$ that satisfy $\\lambda_1 > \\lambda_2 > \\cdots > \\lambda_M$. Therefore, since the variance of the first principal component $Z_1$ is:\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left[ Z_1 \\right] = \\text{Var}\\left[ \\boldsymbol{\\gamma}_1^T \\mathbf{X} \\right] = \\boldsymbol{\\gamma}_1^T \\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_1 = \\boldsymbol{\\gamma}_1^T \\lambda_1\\mathbb{1} \\boldsymbol{\\gamma}_1 = \\lambda_1\\boldsymbol{\\gamma}_1^T\\boldsymbol{\\gamma}_1 = \\lambda_1\\lVert \\boldsymbol{\\gamma_1} \\rVert^2 = \\lambda_1\n",
    "$$\n",
    "\n",
    "this means that the maximum variance of the first principal component corresponds to the largest eigenvalue of the covariance matrix $\\lambda_1$, and the transformation vector $\\boldsymbol{\\gamma}_1$ corresponds to the eigenvector of the covariance matrix associated with this eigenvalue $\\lambda_1$.\n",
    "\n",
    "The second principal component is the linear combination of $X_1, \\dots, X_M$ that has the maximum variance among all linear combinations that are uncorrelated with $Z_1$:\n",
    "\n",
    "$$\n",
    "Z_2 = \\gamma_{12}X_1 + \\gamma_{22}X_2 + \\dots + \\gamma_{M2}X_M = \\sum_{j=1} \\gamma_{j2}X_j = \\boldsymbol{\\gamma}_2^T \\mathbf{X} = \n",
    "\\left( \\gamma_{12}, \\gamma_{22}, \\dots, \\gamma_{M2} \\right)\n",
    "\\begin{bmatrix}\n",
    "X_1 \\\\\n",
    "X_2 \\\\\n",
    "\\vdots \\\\\n",
    "X_M\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\gamma}_2$ is the loading vector for the second principal component, with elements $\\gamma_{12}, \\gamma_{22}, \\dots, \\gamma_{M2}$. Therefore, to find the second principal component, we repeat the process used to find the first component but add the constraint that the first and second principal components are uncorrelated, which is equivalent to saying that $\\text{Cov}(Z_1, Z_2) = 0$. Since:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Cov}(Z_1, Z_2) \n",
    "& = \\text{Cov}(\\boldsymbol{\\gamma}_2^T\\mathbf{X}, \\boldsymbol{\\gamma}_1^T\\mathbf{X}) \\\\\n",
    "& = \\text{Cov}(\\boldsymbol{\\gamma}_2^T\\mathbf{X}, \\mathbf{X}^T\\boldsymbol{\\gamma}_1) \\\\\n",
    "& = \\boldsymbol{\\gamma}_2^T\\text{Cov}(\\mathbf{X}, \\mathbf{X}^T)\\boldsymbol{\\gamma}_1 \\\\\n",
    "& = \\boldsymbol{\\gamma}_2^T\\mathbb{E}\\left[ \\left(\\mathbf{X} - \\boldsymbol{\\mu}_X \\right)\\left(\\mathbf{X} - \\boldsymbol{\\mu}_X \\right)^T \\right]\\boldsymbol{\\gamma}_1, \\,\\,\\, \\text{(using properties of the transpose)} \\\\\n",
    "& = \\boldsymbol{\\gamma}_2^T \\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_1 \\\\\n",
    "& = \\boldsymbol{\\gamma}_2^T \\lambda_1\\mathbb{1} \\boldsymbol{\\gamma}_1 \\\\\n",
    "& \\Rightarrow \\boldsymbol{\\gamma}_2^T \\boldsymbol{\\gamma}_1 = 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "It follows that constraining $Z_2$ to be uncorrelated with $Z_1$ is equivalent to constraining the direction $\\boldsymbol{\\gamma}_2$ to be orthogonal (perpendicular) to the direction $\\boldsymbol{\\gamma}_{1}$. Therefore, finding the second principal component reduces to solving a constrained optimization problem with two conditions:\n",
    "\n",
    "$$\n",
    "\\max_{\\gamma_{12}, \\dots, \\gamma_{M2}} \\left\\{ \\text{Var}\\left[ Z_2 \\right] \\right\\}, \\,\\,\\, \\text{sujeto a} \\,\\,\\, \\lVert \\boldsymbol{\\gamma_2} \\rVert^2 = 1, \\,\\,\\, \\text{y} \\,\\,\\, \\boldsymbol{\\gamma}_2^T\\boldsymbol{\\gamma}_1 = 0\n",
    "$$\n",
    "\n",
    "The Lagrangian for this case is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\gamma}_2) = \\boldsymbol{\\gamma}_2^T\\boldsymbol{\\Sigma} \\boldsymbol{\\gamma}_2 - \\lambda_2\\left( \\boldsymbol{\\gamma}_2^T\\boldsymbol{\\gamma}_2- 1 \\right) - \\alpha\\left( \\boldsymbol{\\gamma}_2^T \\boldsymbol{\\gamma}_1 \\right)\n",
    "$$\n",
    "\n",
    "We seek the critical points of the Lagrangian:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\gamma}_2} \n",
    "& = 2\\Sigma\\boldsymbol{\\gamma}_2 - 2\\lambda_2\\boldsymbol{\\gamma}_2 - \\alpha\\boldsymbol{\\gamma}_1 \\\\\n",
    "& = 2\\boldsymbol{\\gamma}_1^T\\Sigma\\boldsymbol{\\gamma}_2 - 2\\lambda_2\\boldsymbol{\\gamma}_1^T\\boldsymbol{\\gamma}_2 - \\alpha\\boldsymbol{\\gamma}_1^T\\boldsymbol{\\gamma}_1 \\\\\n",
    "& = 2\\boldsymbol{\\gamma}_1^T\\Sigma\\boldsymbol{\\gamma}_2 - 2\\lambda_2\\left(\\boldsymbol{\\gamma}_2^T\\boldsymbol{\\gamma}_1\\right)^T - \\alpha\\lVert \\boldsymbol{\\gamma_1} \\rVert^2 \\\\\n",
    "& = 2\\boldsymbol{\\gamma}_1^T\\lambda_2\\boldsymbol{\\gamma}_2 - \\alpha \\mathbb{1} \\,\\,\\, \\text{(using the eigenvector equation of} \\, \\boldsymbol{\\gamma}_1 \\text{)}\\\\\n",
    "& = - \\alpha \\mathbb{1} \\\\\n",
    "& = \\boldsymbol{0} \\\\ \\\\\n",
    "& \\Rightarrow \\alpha = 0 \\\\ \\\\\n",
    "& \\Rightarrow \\left(\\Sigma - \\lambda_2\\mathbb{1}\\right)\\boldsymbol{\\gamma}_2 = \\boldsymbol{0}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "In this way we obtain another eigenvalue equation and the same strategy of choosing $\\boldsymbol{\\gamma}_2$ as the eigenvector associated with the second largest eigenvalue yields the second principal component.\n",
    "\n",
    "To summarize the procedure, when performing PCA, the first principal component of a set of $M$ variables is the derived variable formed as a linear combination of the original variables that explains the most variance. The second principal component explains the most variance of what remains once the effect of the first component is removed, and we can proceed through $M$ iterations until all the variance is explained. The first principal component can be equivalently defined as a direction that maximizes the variance of the projected data and the $j$-th principal component can be taken as a direction orthogonal to the first $j-1$ principal components that maximize the variance of the projected data.\n",
    "\n",
    "Finally, we can construct a matrix from the $\\boldsymbol{\\gamma}_j$ eigenvectors, namely:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Gamma} = \\left( \\boldsymbol{\\gamma}_1, \\boldsymbol{\\gamma}_2, \\dots, \\boldsymbol{\\gamma}_M \\right) = \n",
    "\\begin{bmatrix}\n",
    "\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1M} \\\\\n",
    "\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2M} \\\\\n",
    "\\vdots      & \\cdots      & \\ddots & \\vdots      \\\\\n",
    "\\gamma_{M1} & \\gamma_{M2} & \\cdots & \\gamma_{MM} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and since the $\\boldsymbol{\\gamma}_j$ are orthonormal to each other, the matrix $\\boldsymbol{\\Gamma}$ will be an orthogonal matrix, i.e. $\\boldsymbol{\\Gamma}^T\\boldsymbol{\\Gamma} = \\mathbb{1}$ which can be understood as a rotation in the feature space, hence PCA reduces to finding a rotation of the coordinate system that maximizes the variance:\n",
    "\n",
    "$$\n",
    "\\mathbf{Z} = \\boldsymbol{\\Gamma} \\mathbf{X}\n",
    "$$\n",
    "\n",
    "The matrix $\\boldsymbol{\\Gamma}$ is precisely the matrix that allows to diagonalize the covariance matrix $\\Sigma$ and whose diagonal elements will be the variances of the new features $\\mathbf{Z}$. Mathematically, this can be expressed as follows:\n",
    "\n",
    "$$\n",
    "\\Lambda = \\text{Var}\\left[ \\mathbf{Z} \\right] = \\text{Var}\\left[ \\boldsymbol{\\Gamma} \\mathbf{X} \\right] = \\boldsymbol{\\Gamma}^T\\Sigma\\boldsymbol{\\Gamma} \\Rightarrow \\Sigma = \\boldsymbol{\\Gamma}\\Lambda \\boldsymbol{\\Gamma}^T\n",
    "$$\n",
    "\n",
    "where $\\Lambda$ takes the form:\n",
    "\n",
    "$$\n",
    "\\Lambda =\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0         & \\cdots & 0         \\\\\n",
    "0         & \\lambda_2 & \\cdots & 0         \\\\\n",
    "\\vdots    & \\vdots    & \\ddots & \\vdots    \\\\\n",
    "0         & 0         & \\cdots & \\lambda_M \\\\\n",
    "\\end{bmatrix}\n",
    ", \\,\\,\\, \\text{donde} \\,\\,\\, \\lambda_i = \\text{Var}\\left[ Z_i \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The proportion of variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When projecting data onto the first principal components, a natural question arises: how much information is lost in this process? In other words, how much of the data's variance is not explained by the first principal components? The proportion of variance explained (PVE) by each principal component gives us a clue about the amount of information retained.\n",
    "\n",
    "The PVE is calculated as the variance explained by each principal component divided by the total variance of the data:\n",
    "\n",
    "$$\n",
    "\\text{PVE}_j = \\frac{\\text{Var}(Z_j)}{\\sum_{j=1}^M \\text{Var}(X_j)} = \\frac{\\lambda_j}{\\text{Tr}\\left( \\Sigma \\right)} = \\frac{\\lambda_j}{\\text{Tr}\\left( \\boldsymbol{\\Gamma}\\Lambda \\boldsymbol{\\Gamma}^T \\right)} = \\frac{\\lambda_j}{\\text{Tr}\\left( \\boldsymbol{\\Gamma}^T\\boldsymbol{\\Gamma}\\Lambda \\right)} = \\frac{\\lambda_j}{\\text{Tr}\\left( \\mathbb{1}\\Lambda \\right)} = \\frac{\\lambda_j}{\\sum_{j=1}^M\\lambda_j} > 0\n",
    "$$\n",
    "\n",
    "By summing the PVE of the first $q$ principal components, we obtain the cumulative PVE, which indicates the amount of variance explained by these components:\n",
    "\n",
    "$$\n",
    "\\text{PVE} = \\frac{\\sum_{j=1}^q\\lambda_j}{\\sum_{j=1}^M\\lambda_j}\n",
    "$$\n",
    "\n",
    "But how many principal components should we use? The answer is not unique and depends on the dataset and the application area. A common approach is to use a scree plot to determine the number of principal components needed to explain a significant amount of the variation in the data. We look for a point where the proportion of variance explained by each principal component decreases, known as the elbow in the scree plot.\n",
    "\n",
    "However, this approach is subjective, and there is no objective way to decide how many principal components are sufficient. In practice, the first principal components are examined to find interesting patterns in the data, and this process continues until no more interesting patterns are found. PCA is generally used as a tool for exploratory data analysis, and this approach reflects its subjective nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology for Maximally Diversified Portfolios Based on PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose a methodology based on Principal Component Analysis (PCA) for constructing maximally diversified portfolios. In uncorrelated markets, the individual values of a generic portfolio $R_{\\mathbf{w}} = \\mathbf{w}^T\\mathbf{R}$ represent additive sources of risk:\r\n",
    "\r\n",
    "$$\r\n",
    "\\text{Var}\\left[ \\tilde{R}_{\\mathbf{w}} \\right] = \\sum_{j=1}^M \\text{Var}\\left[ \\tilde{w}_j \\tilde{R}_j\\right]\r\n",
    "$$\r\n",
    "\r\n",
    "Therefore, in uncorrelated markets, maximum diversification corresponds to equal weights adjusted by variance. In correlated markets, this is not the case. However, even when market values are correlated, it is still possible to identify uncorrelated sources of risk, which are additive. The most natural choice for uncorrelated sources of risk is provided by the principal component decomposition of the covariance of returns.\r\n",
    "\r\n",
    "Our strategy is to decompose the original set of assets into principal portfolios, knowing that these portfolios will be uncorrelated. To optimize diversification, we can set the weights for the principal portfolios as follows:\r\n",
    "\r\n",
    "$$\r\n",
    "\\tilde{w}_j = \\frac{\\frac{1}{\\lambda_j}}{\\sum_{j=1}^M\\frac{1}{\\lambda_j}}, \\,\\,\\, \\sum_{j=1}^M \\tilde{w}_j = 1\r\n",
    "$$\r\n",
    "\r\n",
    "Since, as mentioned above, in uncorrelated markets, maximum diversification corresponds to equal weights adjusted by variance.\r\n",
    "\r\n",
    "On the other hand, we know that the dot product is invariant under rotations, so:\r\n",
    "\r\n",
    "$$\r\n",
    "R_{\\mathbf{w}} = \\mathbf{w}^T\\mathbf{R} = \\mathbf{w}^T\\boldsymbol{\\Gamma}\\boldsymbol{\\Gamma}^T\\mathbf{R} = \\left(\\boldsymbol{\\Gamma}^T\\mathbf{w}\\right)^T\\boldsymbol{\\Gamma}^T\\mathbf{R} =  \\tilde{\\mathbf{w}}^T\\tilde{\\mathbf{R}} = \\tilde{R}_{\\mathbf{w}}\r\n",
    "$$\r\n",
    "\r\n",
    "We observe that a generic portfolio can be viewed as a combination of the original values with weights $\\mathbf{w}$ or as a combination of uncorrelated principal portfolios with weights $\\tilde{\\mathbf{w}} \\equiv \\boldsymbol{\\Gamma}^T \\mathbf{w} = \\boldsymbol{\\Gamma}^{-1}\\mathbf{w}$, and whose returns $\\tilde{R}_{\\mathbf{w}} \\equiv \\boldsymbol{\\Gamma}^TR_{\\mathbf{w}} = \\boldsymbol{\\Gamma}^{-1}R_{\\mathbf{w}}$ are progressively less responsible for the randomness of the portfolio.\r\n",
    "\r\n",
    "Therefore, we can recover the original weights by applying the rotation matrix to the weights $\\tilde{w}_j$.\r\n",
    "\r\n",
    "It is important to highlight that by weighting by the inverse of the variances, the impact of the most volatile assets on the portfolio is reduced, which tends to lower the overall risk. This approach is particularly useful when the assets are uncorrelated or weakly correlated. This strategy offers an effective way to manage risk by giving more weight to assets that are intrinsically less risky. If we apply this strategy in the space of principal portfolios, we would be mitigating the risk of each principal portfolio according to its variance (eigenvalue). The advantages of this strategy are simplicity and ease of implementation, in addition to effectively reducing the total risk of the portfolio, especially when the assets have different levels of volatility. On the other hand, the downside of our approach is that it does not consider the correlation between assets, which may limit the effectiveness of diversification if the assets are highly correlated and may lead to concentration in low-variance assets, potentially limiting the return.\r\n",
    "\r\n",
    "Finally, we note that the weights in our strategy do not necessarily have to be set for all $M$ principal portfolios; they can be adjusted for $q < M$ of them, leaving the remaining weights at 0, depending on the risk profile the investor wishes to assume and the return they want to achieve. This also allows for a reduction in the dimensionality of the problem for portfolios with many assets.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BRK.B']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "C:\\Users\\RJKANG\\AppData\\Local\\Temp\\ipykernel_20460\\1682870701.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  historical_data = pd.concat([historical_data, ticker_data])\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BF.B']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2022-01-01 -> 2023-12-31)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$BF.B: possibly delisted; No price data found  (1d 2022-01-01 -> 2023-12-31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RJKANG\\AppData\\Local\\Temp\\ipykernel_20460\\1682870701.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  historical_data = pd.concat([historical_data, ticker_data])\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GEV']: YFChartError(\"%ticker%: Data doesn't exist for startDate = 1641013200, endDate = 1703998800\")\n",
      "C:\\Users\\RJKANG\\AppData\\Local\\Temp\\ipykernel_20460\\1682870701.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  historical_data = pd.concat([historical_data, ticker_data])\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SW']: YFChartError(\"%ticker%: Data doesn't exist for startDate = 1641013200, endDate = 1703998800\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RJKANG\\AppData\\Local\\Temp\\ipykernel_20460\\1682870701.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  historical_data = pd.concat([historical_data, ticker_data])\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SOLV']: YFChartError(\"%ticker%: Data doesn't exist for startDate = 1641013200, endDate = 1703998800\")\n",
      "C:\\Users\\RJKANG\\AppData\\Local\\Temp\\ipykernel_20460\\1682870701.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  historical_data = pd.concat([historical_data, ticker_data])\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Define date range\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the symbols of S&P 500 companies\n",
    "sp500_tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "tickers = sp500_tickers['Symbol'].tolist()\n",
    "\n",
    "# Create a DataFrame to store relevant variables\n",
    "historical_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each ticker to get relevant data\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Download historical data from Yahoo Finance\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        ticker_data['Ticker'] = ticker\n",
    "        historical_data = pd.concat([historical_data, ticker_data])\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download data for {ticker}: {e}\")\n",
    "\n",
    "# Drop rows with missing data\n",
    "historical_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>149.096985</td>\n",
       "      <td>149.740799</td>\n",
       "      <td>147.023407</td>\n",
       "      <td>148.612045</td>\n",
       "      <td>131.330872</td>\n",
       "      <td>2309117.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>149.230774</td>\n",
       "      <td>151.555191</td>\n",
       "      <td>148.854507</td>\n",
       "      <td>150.693985</td>\n",
       "      <td>133.170715</td>\n",
       "      <td>3016551.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>148.102005</td>\n",
       "      <td>151.989960</td>\n",
       "      <td>147.993317</td>\n",
       "      <td>150.075256</td>\n",
       "      <td>132.623947</td>\n",
       "      <td>3531070.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>151.237457</td>\n",
       "      <td>151.571899</td>\n",
       "      <td>148.444809</td>\n",
       "      <td>148.829437</td>\n",
       "      <td>131.523010</td>\n",
       "      <td>2996458.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>148.938126</td>\n",
       "      <td>150.911377</td>\n",
       "      <td>148.177261</td>\n",
       "      <td>150.459869</td>\n",
       "      <td>132.963837</td>\n",
       "      <td>3349039.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close   Adj Close  \\\n",
       "0 2022-01-03  149.096985  149.740799  147.023407  148.612045  131.330872   \n",
       "1 2022-01-04  149.230774  151.555191  148.854507  150.693985  133.170715   \n",
       "2 2022-01-05  148.102005  151.989960  147.993317  150.075256  132.623947   \n",
       "3 2022-01-06  151.237457  151.571899  148.444809  148.829437  131.523010   \n",
       "4 2022-01-07  148.938126  150.911377  148.177261  150.459869  132.963837   \n",
       "\n",
       "      Volume Ticker  \n",
       "0  2309117.0    MMM  \n",
       "1  3016551.0    MMM  \n",
       "2  3531070.0    MMM  \n",
       "3  2996458.0    MMM  \n",
       "4  3349039.0    MMM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset index\n",
    "historical_data.reset_index(inplace=True)\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "display(historical_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248472 entries, 0 to 248471\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   Date       248472 non-null  datetime64[ns]\n",
      " 1   Open       248472 non-null  float64       \n",
      " 2   High       248472 non-null  float64       \n",
      " 3   Low        248472 non-null  float64       \n",
      " 4   Close      248472 non-null  float64       \n",
      " 5   Adj Close  248472 non-null  float64       \n",
      " 6   Volume     248472 non-null  float64       \n",
      " 7   Ticker     248472 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), object(1)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a CSV file (optional)\n",
    "historical_data.to_csv('sp500_historical_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOVVglnoM60iuQb8Y59tHbX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
